{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "assert sys.version_info >= (3, 7), \"This code requires python version >= 3.7\"\n",
    "import functools\n",
    "import time\n",
    "import click\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "import pprint\n",
    "import tops\n",
    "import tqdm\n",
    "from pathlib import Path\n",
    "from ssd.evaluate import evaluate\n",
    "from ssd import utils\n",
    "from tops.config import instantiate\n",
    "from tops import logger, checkpointer\n",
    "from torch.optim.lr_scheduler import ChainedScheduler\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "def train_epoch(\n",
    "        model, scaler: torch.cuda.amp.GradScaler,\n",
    "        optim, dataloader_train, scheduler,\n",
    "        gpu_transform: torch.nn.Module,\n",
    "        log_interval: int):\n",
    "    grad_scale = scaler.get_scale()\n",
    "    for batch in tqdm.tqdm(dataloader_train, f\"Epoch {logger.epoch()}\"):\n",
    "        batch = tops.to_cuda(batch)\n",
    "        batch[\"labels\"] = batch[\"labels\"].long()\n",
    "        batch = gpu_transform(batch)\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=tops.AMP()):\n",
    "            bbox_delta, confs = model(batch[\"image\"])\n",
    "            loss, to_log = model.loss_func(bbox_delta, confs, batch[\"boxes\"], batch[\"labels\"])\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optim)\n",
    "        scaler.update()\n",
    "        optim.zero_grad()\n",
    "        if grad_scale == scaler.get_scale():\n",
    "            scheduler.step()\n",
    "            if logger.global_step() % log_interval:\n",
    "                logger.add_scalar(\"stats/learning_rate\", scheduler._schedulers[-1].get_last_lr()[-1])\n",
    "        else:\n",
    "            grad_scale = scaler.get_scale()\n",
    "            logger.add_scalar(\"amp/grad_scale\", scaler.get_scale())\n",
    "        if logger.global_step() % log_interval == 0:\n",
    "            to_log = {f\"loss/{k}\": v.mean().cpu().item() for k, v in to_log.items()}\n",
    "            logger.add_dict(to_log)\n",
    "        # torch.cuda.amp skips gradient steps if backward pass produces NaNs/infs.\n",
    "        # If it happens in the first iteration, scheduler.step() will throw exception\n",
    "        logger.step()\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def print_config(cfg):\n",
    "    container = OmegaConf.to_container(cfg)\n",
    "    pp = pprint.PrettyPrinter(indent=2, compact=False)\n",
    "    print(\"--------------------Config file below--------------------\")\n",
    "    pp.pprint(container)\n",
    "    print(\"--------------------End of config file--------------------\")\n",
    "\n",
    "\n",
    "def train(config_path=\"./configs/ssd300.py\", evaluate_only: bool=False):\n",
    "    logger.logger.DEFAULT_SCALAR_LEVEL = logger.logger.DEBUG\n",
    "    cfg = utils.load_config(config_path)\n",
    "    print_config(cfg)\n",
    "\n",
    "    tops.init(cfg.output_dir)\n",
    "    tops.set_AMP(cfg.train.amp)\n",
    "    tops.set_seed(cfg.train.seed)\n",
    "    dataloader_train = instantiate(cfg.data_train.dataloader)\n",
    "    dataloader_val = instantiate(cfg.data_val.dataloader)\n",
    "    cocoGt = dataloader_val.dataset.get_annotations_as_coco()\n",
    "    model = tops.to_cuda(instantiate(cfg.model))\n",
    "    optimizer = instantiate(cfg.optimizer, params=utils.tencent_trick(model))\n",
    "    scheduler = ChainedScheduler(instantiate(list(cfg.schedulers.values()), optimizer=optimizer))\n",
    "    checkpointer.register_models(\n",
    "        dict(model=model, optimizer=optimizer, scheduler=scheduler))\n",
    "    total_time = 0\n",
    "    if checkpointer.has_checkpoint():\n",
    "        train_state = checkpointer.load_registered_models(load_best=False)\n",
    "        total_time = train_state[\"total_time\"]\n",
    "        logger.log(f\"Resuming train from: epoch: {logger.epoch()}, global step: {logger.global_step()}\")\n",
    "\n",
    "    gpu_transform_val = instantiate(cfg.data_val.gpu_transform)\n",
    "    gpu_transform_train = instantiate(cfg.data_train.gpu_transform)\n",
    "    evaluation_fn = functools.partial(\n",
    "        evaluate,\n",
    "        model=model,\n",
    "        dataloader=dataloader_val,\n",
    "        cocoGt=cocoGt,\n",
    "        gpu_transform=gpu_transform_val,\n",
    "        label_map=cfg.label_map\n",
    "    )\n",
    "    if evaluate_only:\n",
    "        evaluation_fn()\n",
    "        exit()\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=tops.AMP())\n",
    "    dummy_input = tops.to_cuda(torch.randn(1, cfg.train.image_channels, *cfg.train.imshape))\n",
    "    tops.print_module_summary(model, (dummy_input,))\n",
    "    start_epoch = logger.epoch()\n",
    "    for epoch in range(start_epoch, cfg.train.epochs):\n",
    "        start_epoch_time = time.time()\n",
    "        train_epoch(model, scaler, optimizer, dataloader_train, scheduler, gpu_transform_train, cfg.train.log_interval)\n",
    "        end_epoch_time = time.time() - start_epoch_time\n",
    "        total_time += end_epoch_time\n",
    "        logger.add_scalar(\"stats/epoch_time\", end_epoch_time)\n",
    "\n",
    "        eval_stats = evaluation_fn()\n",
    "        eval_stats = {f\"metrics/{key}\": val for key, val in eval_stats.items()}\n",
    "        logger.add_dict(eval_stats, level=logger.logger.INFO)\n",
    "        train_state = dict(total_time=total_time)\n",
    "        checkpointer.save_registered_models(train_state)\n",
    "        logger.step_epoch()\n",
    "    logger.add_scalar(\"stats/total_time\", total_time)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
